{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAT\n",
    "\n",
    "> wip..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.basics import *\n",
    "from fastai.test_utils import synth_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ALUMCallback(Callback):\n",
    "    \"ALUM callback (draft)\"\n",
    "    run_valid=False\n",
    "\n",
    "    def __init__(self, m, start_iter=None): #?? potentially start in the middle of training\n",
    "        self.m = m\n",
    "\n",
    "    def after_loss(self):\n",
    "        #TODO: detach as appropriate\n",
    "        old_weight = self.m.weight.data\n",
    "        logits = self.pred\n",
    "        print(f'{self.train_iter:2} - Do stuff here with weights of shape {old_weight.shape} and logits {logits.shape} and modify loss {self.loss:.4f}')\n",
    "        # do ALUM stuff here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(1,10, bias=False),\n",
    "    nn.Linear(10,1, bias=False)\n",
    ")\n",
    "learn = synth_learner(model=model, cbs=ALUMCallback(model[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Fit\n",
      "   - before_fit     : [TrainEvalCallback, Recorder]\n",
      "  Start Epoch Loop\n",
      "     - before_epoch   : [Recorder]\n",
      "    Start Train\n",
      "       - before_train   : [TrainEvalCallback, Recorder]\n",
      "      Start Batch Loop\n",
      "         - before_batch   : []\n",
      "         - after_pred     : []\n",
      "         - after_loss     : [ALUMCallback]\n",
      "         - before_backward: []\n",
      "         - before_step    : []\n",
      "         - after_step     : []\n",
      "         - after_cancel_batch: []\n",
      "         - after_batch    : [TrainEvalCallback, Recorder]\n",
      "      End Batch Loop\n",
      "    End Train\n",
      "     - after_cancel_train: [Recorder]\n",
      "     - after_train    : [Recorder]\n",
      "    Start Valid\n",
      "       - before_validate: [TrainEvalCallback, Recorder]\n",
      "      Start Batch Loop\n",
      "         - **CBs same as train batch**: []\n",
      "      End Batch Loop\n",
      "    End Valid\n",
      "     - after_cancel_validate: [Recorder]\n",
      "     - after_validate : [Recorder]\n",
      "  End Epoch Loop\n",
      "   - after_cancel_epoch: []\n",
      "   - after_epoch    : [Recorder]\n",
      "End Fit\n",
      " - after_cancel_fit: []\n",
      " - after_fit      : []\n"
     ]
    }
   ],
   "source": [
    "learn.show_training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 - Do stuff here with weights of shape torch.Size([10, 1]) and logits torch.Size([16, 1]) and modify loss 13.3856\n",
      " 1 - Do stuff here with weights of shape torch.Size([10, 1]) and logits torch.Size([16, 1]) and modify loss 14.8628\n",
      " 2 - Do stuff here with weights of shape torch.Size([10, 1]) and logits torch.Size([16, 1]) and modify loss 8.4519\n",
      " 3 - Do stuff here with weights of shape torch.Size([10, 1]) and logits torch.Size([16, 1]) and modify loss 16.2656\n",
      " 4 - Do stuff here with weights of shape torch.Size([10, 1]) and logits torch.Size([16, 1]) and modify loss 13.1633\n",
      " 5 - Do stuff here with weights of shape torch.Size([10, 1]) and logits torch.Size([16, 1]) and modify loss 10.4453\n",
      " 6 - Do stuff here with weights of shape torch.Size([10, 1]) and logits torch.Size([16, 1]) and modify loss 10.9737\n",
      " 7 - Do stuff here with weights of shape torch.Size([10, 1]) and logits torch.Size([16, 1]) and modify loss 14.0253\n",
      " 8 - Do stuff here with weights of shape torch.Size([10, 1]) and logits torch.Size([16, 1]) and modify loss 13.0633\n",
      " 9 - Do stuff here with weights of shape torch.Size([10, 1]) and logits torch.Size([16, 1]) and modify loss 10.7256\n",
      "[0, 12.508787155151367, 12.020278930664062, '00:00']\n"
     ]
    }
   ],
   "source": [
    "learn.fit(1, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class VATCallback(Callback):\n",
    "    \"VAT callback (draft)\"\n",
    "    run_valid=False\n",
    "    # mb worth adding capability to inject adversarial noize into intermediate activations\n",
    "    # for ALUM case we could perturb outputs of the embedding layer instead of embedding weights (which would be equivalent)\n",
    "    def __init__(self, start_iter=None): #?? potentially start in the middle of training\n",
    "        \n",
    "        self.start_iter = start_iter\n",
    "        \n",
    "    def after_loss(self):\n",
    "        #TODO: detach as appropriate\n",
    "        noize = 0\n",
    "        x_adv = self.x + noize #?? take care of possible multiple inputs \n",
    "        logits = self.pred\n",
    "        print(f'{self.train_iter:2} - Do stuff here with input of shape {self.x.shape} and logits {logits.shape} and modify loss {self.loss:.4f}')\n",
    "        # do VAT stuff here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 - Do stuff here with input of shape torch.Size([16, 1]) and logits torch.Size([16, 1]) and modify loss 12.9000\n",
      " 1 - Do stuff here with input of shape torch.Size([16, 1]) and logits torch.Size([16, 1]) and modify loss 9.6923\n",
      " 2 - Do stuff here with input of shape torch.Size([16, 1]) and logits torch.Size([16, 1]) and modify loss 10.2626\n",
      " 3 - Do stuff here with input of shape torch.Size([16, 1]) and logits torch.Size([16, 1]) and modify loss 14.6588\n",
      " 4 - Do stuff here with input of shape torch.Size([16, 1]) and logits torch.Size([16, 1]) and modify loss 16.4393\n",
      " 5 - Do stuff here with input of shape torch.Size([16, 1]) and logits torch.Size([16, 1]) and modify loss 7.8181\n",
      " 6 - Do stuff here with input of shape torch.Size([16, 1]) and logits torch.Size([16, 1]) and modify loss 11.3965\n",
      " 7 - Do stuff here with input of shape torch.Size([16, 1]) and logits torch.Size([16, 1]) and modify loss 13.6873\n",
      " 8 - Do stuff here with input of shape torch.Size([16, 1]) and logits torch.Size([16, 1]) and modify loss 14.5875\n",
      " 9 - Do stuff here with input of shape torch.Size([16, 1]) and logits torch.Size([16, 1]) and modify loss 12.5698\n",
      "[0, 12.431605339050293, 10.528060913085938, '00:00']\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(1,10, bias=False),\n",
    "    nn.Linear(10,1, bias=False)\n",
    ")\n",
    "learn = synth_learner(model=model, cbs=VATCallback())\n",
    "learn.fit(1, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torchenv]",
   "language": "python",
   "name": "conda-env-torchenv-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
