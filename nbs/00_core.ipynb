{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAT\n",
    "\n",
    "> wip..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.basics import *\n",
    "from fastai.test_utils import synth_learner\n",
    "from fastai.callback.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALUM\n",
    "\n",
    "Adversarial training for large neural language models as presented in https://arxiv.org/abs/2004.08994."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def hook_out(m, inp, out):\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def KL(inp, targ, reduction=\"sum\"):\n",
    "    input = input.float()\n",
    "    target = target.float()\n",
    "    return F.kl_div(F.log_softmax(inp, dim=-1, dtype=torch.float32), F.softmax(targ, dim=-1, dtype=torch.float32), reduction=reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def SymmetrizedKL(inp, targ, reduction=\"sum\"):\n",
    "    return KL(inp, targ.detach(), reduction=reduction) + KL(targ, inp.detach(), reduction=reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def adv_project(grad, norm_type='inf', eps=1e-6):\n",
    "    if norm_type == 'l2':\n",
    "        direction = grad / (torch.norm(grad, dim=-1, keepdim=True) + eps)\n",
    "    elif norm_type == 'l1':\n",
    "        direction = grad.sign()\n",
    "    else:\n",
    "        direction = grad / (grad.abs().max(-1, keepdim=True)[0] + eps)\n",
    "    return direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def compute_adversarial_loss(model:nn.Module, embed:Tensor, logits:Tensor,\n",
    "                             special_tokens_mask=None, token_type_mask=None,\n",
    "                             noise_var:float=1e-5, step_size:float=1e-3, k:int=1,\n",
    "                             noise_gamma:float=1e-6, criterion=SymmetrizedKL):\n",
    "    \"Computes adversarial loss on iteratively refined perturbation\"\n",
    "    noise = embed.data.new(embed.size()).normal_(0, noise_var)\n",
    "    noise.requires_grad_();\n",
    "    if special_tokens_mask is not None:\n",
    "        noise = noise*special_tokens_mask\n",
    "    if token_type_mask is not None:\n",
    "        nosie = noise*token_type_mask\n",
    "\n",
    "    for _ in range(k):\n",
    "        newembed = embed + noise\n",
    "        adv_logits = model(inputs_embeds=newembed).logits\n",
    "\n",
    "        adv_loss = KL(adv_logits, logits.detach(), reduction=\"batchmean\")\n",
    "        delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True)\n",
    "\n",
    "        norm = torch.linalg.norm(delta_grad)\n",
    "        if (torch.isnan(norm) or torch.isinf(norm)):\n",
    "            break\n",
    "        noise = noise + delta_grad * step_size\n",
    "        noise = adv_project(noise, norm_type=\"fro\", eps=noise_gamma)\n",
    "\n",
    "    newembed = embed + noise\n",
    "    adv_logits = model(inputs_embeds=newembed).logits\n",
    "\n",
    "    return criterion(adv_logits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "class ALUMCallback(Callback):\n",
    "    \"ALUM callback for HuggingFace pretrained models\"\n",
    "    run_valid = False\n",
    "    order = GradientAccumulation.order-1\n",
    "    @delegates(compute_adversarial_loss)\n",
    "    def __init__(self, m:nn.Module, alpha:float=1., start_epoch:int=0,\n",
    "                 criterion=None, mask_special_tokens:bool=False, \n",
    "                 one_token_type=False, **kwargs):\n",
    "        self.hook = None\n",
    "        self.kwargs = kwargs if kwargs else {}\n",
    "        self._do_vat=True\n",
    "        self.special_tokens_mask, self.token_type_mask = None, None\n",
    "        store_attr()\n",
    "    \n",
    "    def before_fit(self):\n",
    "        if self.criterion is None:\n",
    "            self.criterion = MSELoss() if isinstance(self.loss_func, nn.MSELoss) else SymmetrizedKL\n",
    "        self.adv_loss_func = partial(compute_adversarial_loss, criterion=self.criterion, **self.kwargs)\n",
    "    \n",
    "    def before_batch(self):\n",
    "        if (self.hook is None) and (self.epoch >= self.start_epoch):\n",
    "            self.hook = Hook(self.m, hook_out)\n",
    "            print(f'Starting virtual adversarial training at epoch {self.epoch}')\n",
    "\n",
    "        if self.mask_special_tokens:\n",
    "            self.special_tokens_mask = self.xb[0].pop('special_tokens_mask', None)\n",
    "            if self.special_tokens_mask is not None:\n",
    "                self.special_tokens_mask = (1-self.special_tokens_mask).unsqueeze(-1)\n",
    "        if self.one_token_type:\n",
    "            self.token_type_mask = self.xb[0].pop('token_type_ids', None)\n",
    "            if self.token_type_mask is not None:\n",
    "                # this would deterministically mask tokens of type 0\n",
    "                self.token_type_mask = self.token_type_mask.unsqueeze(-1)\n",
    "\n",
    "    def after_loss(self):\n",
    "        if self.epoch >= self.start_epoch and self._do_vat:\n",
    "            embed, logits = self.hook.stored, self.pred\n",
    "            model = self.model.hf_model if hasattr(self.model, 'hf_model') else self.model\n",
    "            try:    adv_loss = self.adv_loss_func(model, embed, logits, self.special_tokens_mask, self.token_type_mask)\n",
    "            except TypeError as e:\n",
    "                print(\"Your model is probably not supported, make sure model interface is compatible with HF pretrained models\")\n",
    "                adv_loss, self._do_vat = 0, False\n",
    "            self.learn.loss_grad += adv_loss * self.alpha\n",
    "\n",
    "    def after_fit(self):\n",
    "        if self.hook is not None: self.hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(1,10, bias=False),\n",
    "    nn.Linear(10,1, bias=False)\n",
    ")\n",
    "learn = synth_learner(model=model, cbs=ALUMCallback(model[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Fit\n",
      "   - before_fit     : [TrainEvalCallback, ALUMCallback, Recorder, ProgressCallback]\n",
      "  Start Epoch Loop\n",
      "     - before_epoch   : [Recorder, ProgressCallback]\n",
      "    Start Train\n",
      "       - before_train   : [TrainEvalCallback, Recorder, ProgressCallback]\n",
      "      Start Batch Loop\n",
      "         - before_batch   : [ALUMCallback]\n",
      "         - after_pred     : []\n",
      "         - after_loss     : [ALUMCallback]\n",
      "         - before_backward: []\n",
      "         - before_step    : []\n",
      "         - after_step     : []\n",
      "         - after_cancel_batch: []\n",
      "         - after_batch    : [TrainEvalCallback, Recorder, ProgressCallback]\n",
      "      End Batch Loop\n",
      "    End Train\n",
      "     - after_cancel_train: [Recorder]\n",
      "     - after_train    : [Recorder, ProgressCallback]\n",
      "    Start Valid\n",
      "       - before_validate: [TrainEvalCallback, Recorder, ProgressCallback]\n",
      "      Start Batch Loop\n",
      "         - **CBs same as train batch**: []\n",
      "      End Batch Loop\n",
      "    End Valid\n",
      "     - after_cancel_validate: [Recorder]\n",
      "     - after_validate : [Recorder, ProgressCallback]\n",
      "  End Epoch Loop\n",
      "   - after_cancel_epoch: []\n",
      "   - after_epoch    : [Recorder]\n",
      "End Fit\n",
      " - after_cancel_fit: []\n",
      " - after_fit      : [ALUMCallback, ProgressCallback]\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "learn.show_training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12.705046</td>\n",
       "      <td>7.071889</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>11.292135</td>\n",
       "      <td>8.504992</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting virtual adversarial training at epoch 0\n",
      "Your model is probably not supported, make sure model interface is compatible with HF pretrained models\n"
     ]
    }
   ],
   "source": [
    "learn.fit(2, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class VATCallback(Callback):\n",
    "    \"VAT callback (draft)\"\n",
    "    run_valid=False\n",
    "    # mb worth adding capability to inject adversarial noize into intermediate activations\n",
    "    # for ALUM case we could perturb outputs of the embedding layer instead of embedding weights (which would be equivalent)\n",
    "    def __init__(self, start_iter=None): #?? potentially start in the middle of training\n",
    "        \n",
    "        self.start_iter = start_iter\n",
    "        \n",
    "    def after_loss(self):\n",
    "        #TODO: detach as appropriate\n",
    "        noize = 0\n",
    "        x_adv = self.x + noize #?? take care of possible multiple inputs \n",
    "        logits = self.pred\n",
    "        print(f'{self.train_iter:2} - Do stuff here with input of shape {self.x.shape} and logits {logits.shape} and modify loss {self.loss:.4f}')\n",
    "        # do VAT stuff here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10.577516</td>\n",
       "      <td>10.631283</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 - Do stuff here with input of shape torch.Size([16, 1]) and logits torch.Size([16, 1]) and modify loss 14.7863\n",
      " 1 - Do stuff here with input of shape torch.Size([16, 1]) and logits torch.Size([16, 1]) and modify loss 14.5227\n",
      " 2 - Do stuff here with input of shape torch.Size([16, 1]) and logits torch.Size([16, 1]) and modify loss 8.2985\n",
      " 3 - Do stuff here with input of shape torch.Size([16, 1]) and logits torch.Size([16, 1]) and modify loss 11.5245\n",
      " 4 - Do stuff here with input of shape torch.Size([16, 1]) and logits torch.Size([16, 1]) and modify loss 10.8708\n",
      " 5 - Do stuff here with input of shape torch.Size([16, 1]) and logits torch.Size([16, 1]) and modify loss 9.9784\n",
      " 6 - Do stuff here with input of shape torch.Size([16, 1]) and logits torch.Size([16, 1]) and modify loss 8.0394\n",
      " 7 - Do stuff here with input of shape torch.Size([16, 1]) and logits torch.Size([16, 1]) and modify loss 8.8918\n",
      " 8 - Do stuff here with input of shape torch.Size([16, 1]) and logits torch.Size([16, 1]) and modify loss 9.1311\n",
      " 9 - Do stuff here with input of shape torch.Size([16, 1]) and logits torch.Size([16, 1]) and modify loss 10.5645\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(1,10, bias=False),\n",
    "    nn.Linear(10,1, bias=False)\n",
    ")\n",
    "learn = synth_learner(model=model, cbs=VATCallback())\n",
    "learn.fit(1, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torchenv]",
   "language": "python",
   "name": "conda-env-torchenv-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
