{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 22 14:24:48 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.05    Driver Version: 450.51.05    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100S-PCI...  Off  | 00000000:00:0A.0 Off |                    0 |\n",
      "| N/A   51C    P0   224W / 250W |  26383MiB / 32510MiB |     99%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install -Uqq fastcore sentencepiece\n",
    "    !pip install -Uqq --no-deps fastai\n",
    "    !pip install -Uqq transformers datasets wandb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "from transformers import *\n",
    "from datasets import load_dataset, concatenate_datasets, load_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'roberta-base'\n",
    "# data\n",
    "max_length = 128\n",
    "bs = 16\n",
    "val_bs = bs*4\n",
    "# training\n",
    "lr = 3e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_name = 'imdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/workspace/.cache/imdb/plain_text/1.0.0/90099cb476936b753383ba2ae6ab2eae419b2e87f71cd5189cb9c8e5814d12a3)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds = train_ds.select(range(100))\n",
    "# valid_ds = valid_ds.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['label', 'text'],\n",
       " 'test': ['label', 'text'],\n",
       " 'unsupervised': ['label', 'text']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': -1,\n",
       " 'text': \"Everybody has seen 'Back To The Future,' right? Whether you LIKE that movie or not, you've seen an example of how to make a time-travel movie work. A torn-up poster for 'Back To The Future' shows up in this movie, representing, perhaps unintentionally, what the makers of 'Tangents' (aka 'Time Chasers') did to the time-travel formula. Then again, the movie claims to have been made in 1994, but it looks -- and sounds -- like it was produced at least ten years earlier, so maybe they achieved time-travel after all.<br /><br />Start with an intensely unappealing leading man. I mean, what woman doesn't love gangly, whiny, lantern-jawed, butt-chinned, mullet-men with Coke-bottle glasses? Oh, none of you? Prepare to tough it out, ladies, cuz that's what this movie gives you.<br /><br />Second, add a leading lady who -- while not entirely unattractive -- represents many '80s clichés: big hair, too much makeup, two different plaids, shoulder pads, acid-washed mom-jeans, etc.<br /><br />Throw in a Michael Medved look-alike who wears pink blazers with white pants, a stunningly transparent villain who talks like Mortimer Snerd and has an office that looks like a circus-themed library, and evil henchmen who have nothing better to do than direct air traffic. That's our cast, folks. Enjoy!<br /><br />I could try to explain the plot, but it will take a lot less time for you to just track down a copy of this movie and watch it yourself. If YOU figure out the plot, please don't hesitate to share it with me.<br /><br />I would strongly advise watching this movie with the help of the folks at Mystery Science Theater 3000. I don't think it could stand on its own.<br /><br />The film, 'Tangents': 3 stars -- at least they tried.<br /><br />MST3K's 'Time Chasers' episode: 8 stars -- they actually succeeded.\"}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['unsupervised'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'],return_attention_mask=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f677b64f3c14f36a31c51b2d7afbec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#0', max=63.0, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f67a799fc34930ba277541241a996c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#3', max=63.0, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d53f4100ff4cc38c0fd12b9a348a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#1', max=63.0, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df78ad511ab44479276737694b104b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#2', max=63.0, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d067d89548844fab0c6791243a616d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#3', max=63.0, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf053e73ef3e426e9a841878759cf6ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#0', max=63.0, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918be37d232e44ff8563867f547967d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#1', max=63.0, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f70f0d249a45c0a8f7f3642f826f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#2', max=63.0, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(tokenize, batched=True, batch_size=100, remove_columns=train_ds.column_names, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_datasets = datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_dataset = concatenate_datasets([lm_dataset['train'], lm_dataset['unsuperwised'], lm_dataset['test']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "\n",
    "# WANDB_NAME = f'{ds_name}-{model_name}-hf'\n",
    "# GROUP = f'{ds_name}-{model_name}-hf-{lr:.0e}'\n",
    "# NOTES = f'HF finetuning {model_name} with AdamW lr={lr:.0e}'\n",
    "# CONFIG = {}\n",
    "# TAGS =[model_name,ds_name,'adamw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "WANDB_NAME = f'{ds_name}-{model_name}-alum'\n",
    "GROUP = f'{ds_name}-{model_name}-hf-{lr:.0e}'\n",
    "NOTES = f'HF finetuning {model_name} with AdamW lr={lr:.0e}'\n",
    "CONFIG = {}\n",
    "TAGS =[model_name,ds_name,'adamw','alum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_LOG_MODEL=false\n",
      "env: WANDB_WATCH=false\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_LOG_MODEL = false\n",
    "%env WANDB_WATCH = false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfastai_community\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.27 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">imdb-roberta-base-alum</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/fastai_community/vat\" target=\"_blank\">https://wandb.ai/fastai_community/vat</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/fastai_community/vat/runs/3hbp5ywy\" target=\"_blank\">https://wandb.ai/fastai_community/vat/runs/3hbp5ywy</a><br/>\n",
       "                Run data is saved locally in <code>/workspace/wav2vec/wandb/run-20210422_134932-3hbp5ywy</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(reinit=True, project=\"vat\", entity=\"fastai_community\",\n",
    "           name=WANDB_NAME, group=GROUP, notes=NOTES, tags=TAGS, config=CONFIG);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    'test', #f'{ds_name}-{model_name}-2',\n",
    "    evaluation_strategy = 'epoch',\n",
    "    per_device_train_batch_size = bs,\n",
    "    per_device_eval_batch_size=val_bs,\n",
    "    learning_rate=lr,\n",
    "    num_train_epochs=5,\n",
    "    lr_scheduler_type='cosine',\n",
    "    warmup_ratio=0.2,\n",
    "    logging_steps=200,\n",
    "    fp16=True,\n",
    "    group_by_length=True,\n",
    "    dataloader_num_workers=4,\n",
    "    remove_unused_columns=False,\n",
    "    report_to='none',#'wandb',\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=2,\n",
    "    seed=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model,\n",
    "#     training_args,\n",
    "#     train_dataset=train_ds,\n",
    "#     eval_dataset=valid_ds,\n",
    "#     tokenizer=tokenizer,\n",
    "#     # data_collator=DataCollatorWithPadding(),\n",
    "#     compute_metrics=compute_metric\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VATrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import compute_adversarial_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VATrainer(Trainer):\n",
    "\n",
    "    def __init__(self, *args, vat_kwargs={}, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.adv_alpha = vat_kwargs.pop('alpha', 1.)\n",
    "        self.mask_special_tokens = vat_kwargs.pop('mask_special_tokens', False)\n",
    "        self.one_token_type = vat_kwargs.pop('one_token_type', False)\n",
    "        self.vat_start_epoch = vat_kwargs.pop('start_epoch', 1)\n",
    "        self.vat_kwargs = vat_kwargs\n",
    "        self._do_vat=False\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        \"\"\"\n",
    "        Loss computation with virtual adversarial loss component \n",
    "        \"\"\"\n",
    "        if self.label_smoother is not None and \"labels\" in inputs:\n",
    "            labels = inputs.pop(\"labels\")\n",
    "        else:\n",
    "            labels = None\n",
    "        # if masking any of those are expected to be in the inputs and should be removed before forward\n",
    "        special_tokens_mask = inputs.pop('special_tokens_mask', None)\n",
    "        token_type_mask = inputs.pop('token_type_ids', None)\n",
    "        # explicitly adding kwargs here, verify no conflicts may happen\n",
    "        outputs = model(**inputs, output_hidden_states=model.training, return_dict=True)\n",
    "        # Save past state if it exists\n",
    "        # TODO: this needs to be fixed and made cleaner later.\n",
    "        if self.args.past_index >= 0:\n",
    "            self._past = outputs[self.args.past_index]\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = self.label_smoother(outputs, labels)\n",
    "        else:\n",
    "            loss = outputs.loss\n",
    "        #TODO add option to use vat_start_step\n",
    "        if model.training and self.state.epoch >= self.vat_start_epoch:\n",
    "            if not self._do_vat:\n",
    "                print(f'Starting virtual adversarial training at epoch {self.state.epoch}')\n",
    "                self._do_vat = True\n",
    "            # ALUM training procedure\n",
    "            embed = outputs.hidden_states[0].detach()\n",
    "            # TODO add option mask special tokens or toke types here\n",
    "            special_tokens_mask, token_type_mask = None, None\n",
    "            if self.mask_special_tokens:\n",
    "                if special_tokens_mask is not None:\n",
    "                    special_tokens_mask = (1-special_tokens_mask).unsqueeze(-1)\n",
    "                else:\n",
    "                    print('`special_tokens_maks` not found in the inputs')\n",
    "                    self.mask_special_tokens = False\n",
    "            if self.one_token_type:\n",
    "                token_type_mask = None\n",
    "\n",
    "            adv_loss = compute_adversarial_loss(model, embed, outputs.logits, \n",
    "                special_tokens_mask=special_tokens_mask, token_type_mask=token_type_mask,\n",
    "                **self.vat_kwargs)\n",
    "            loss += self.adv_alpha*adv_loss\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = len(lm_dataset)\n",
    "tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = list(range(int(tot*0.95)))\n",
    "valid_idx = list(range(int(tot*0.95), tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)\n",
    "\n",
    "vat_kwargs = {\n",
    "    'start_epoch':0,\n",
    "    'alpha':.5,\n",
    "    'mask_special_tokens':True\n",
    "}\n",
    "\n",
    "trainer = VATrainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=lm_dataset.select(train_idx),\n",
    "    eval_dataset=lm_dataset.select(valid_idx),\n",
    "    data_collator=data_collator(),\n",
    "    compute_metrics=compute_metric,\n",
    "    vat_kwargs=vat_kwargs    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting virtual adversarial training at epoch 0\n",
      "`special_tokens_maks` not found in the inputs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='3500' max='7815' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3500/7815 32:54 < 40:35, 1.77 it/s, Epoch 2.24/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.481100</td>\n",
       "      <td>0.210747</td>\n",
       "      <td>0.931360</td>\n",
       "      <td>250.013300</td>\n",
       "      <td>99.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.303600</td>\n",
       "      <td>0.143070</td>\n",
       "      <td>0.949600</td>\n",
       "      <td>249.983200</td>\n",
       "      <td>100.007000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# del model, trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
