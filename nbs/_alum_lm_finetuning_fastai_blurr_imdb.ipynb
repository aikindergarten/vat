{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 15 14:53:23 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   66C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install -Uqq fastcore onnx onnxruntime sentencepiece seqeval rouge-score\n",
    "    !pip install -Uqq --no-deps fastai ohmeow-blurr\n",
    "    !pip install -Uqq transformers datasets wandb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *\n",
    "from fastai.callback.wandb import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(fn):\n",
    "    return open(fn).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB)\n",
    "# path = untar_data(URLs.IMDB_SAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'distilbert-base-uncased'\n",
    "\n",
    "max_len = 512\n",
    "bs = 4\n",
    "val_bs = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "WANDB_NAME = f'imdb-{model_name}-alum'\n",
    "GROUP = f'IMDB-{model_name}-alum'\n",
    "NOTES = f'Simple finetuning {model_name} with RAdam lr=2e-5'\n",
    "CONFIG = {}\n",
    "TAGS =[model_name,'imdb','radam','alum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfastai_community\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.26<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">imdb-distilbert-base-uncased-alum</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/fastai_community/vat\" target=\"_blank\">https://wandb.ai/fastai_community/vat</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/fastai_community/vat/runs/3w4oa5js\" target=\"_blank\">https://wandb.ai/fastai_community/vat/runs/3w4oa5js</a><br/>\n",
       "                Run data is saved locally in <code>/content/wandb/run-20210415_145336-3w4oa5js</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(reinit=True, project=\"vat\", entity=\"fastai_community\",\n",
    "           name=WANDB_NAME, group=GROUP, notes=NOTES, tags=TAGS, config=CONFIG);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_device(e, device):\n",
    "    if hasattr(e, 'to'): return e.to(device)\n",
    "    elif isinstance(e, dict):\n",
    "        for _, v in e.items():\n",
    "            if hasattr(v, 'to'): v.to(device)\n",
    "        return {k:(v.to(device) if hasattr(v, 'to') else v) for k, v in e.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def one_batch(self:Learner, i, b):\n",
    "        self.iter = i\n",
    "        b_on_device = tuple(_to_device(e, self.dls.device) for e in b) if self.dls.device is not None else b\n",
    "        self._split(b_on_device)\n",
    "        self._with_events(self._do_one_batch, 'batch', CancelBatchException)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from transformers import *\n",
    "\n",
    "from blurr.data.all import *\n",
    "from blurr.modeling.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(model_name, model_cls=AutoModelForSequenceClassification,\n",
    "                                                                               tokenizer_cls=AutoTokenizer, tokenizer_kwargs={'max_len':512})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = (HF_TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), CategoryBlock)\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_items=get_text_files,\n",
    "                   get_x = read_text,\n",
    "                   get_y=parent_label,\n",
    "                   splitter=GrandparentSplitter(valid_name='test'))\n",
    "\n",
    "dls = dblock.dataloaders(path, bs=bs, val_bs=val_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts = pd.read_csv(path/'texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blocks = (HF_TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), CategoryBlock)\n",
    "# dblock = DataBlock(blocks=blocks,\n",
    "#                    get_x = ColReader('text'),\n",
    "#                    get_y = ColReader('label'),\n",
    "#                    splitter = ColSplitter()\n",
    "#                    )\n",
    "\n",
    "# dls = dblock.dataloaders(texts, bs=bs, val_bs=val_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = HF_BaseModelWrapper(hf_model)\n",
    "# learn = Learner(dls,\n",
    "#                 model,\n",
    "#                 opt_func=RAdam,\n",
    "#                 metrics=[accuracy],\n",
    "#                 cbs=[HF_BaseModelCallback],\n",
    "#                 splitter=hf_splitter).to_fp16()\n",
    "\n",
    "# learn.blurr_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.show_training_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vat finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import linalg as LA\n",
    "\n",
    "def KL(input, target, reduction=\"sum\"):\n",
    "    input = input.float()\n",
    "    target = target.float()\n",
    "    loss = F.kl_div(F.log_softmax(input, dim=-1, dtype=torch.float32), F.softmax(target, dim=-1, dtype=torch.float32), reduction=reduction)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callback.all import Hook\n",
    "\n",
    "def hook_out(m, inp, out):\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_project(grad, norm_type='inf', eps=1e-6):\n",
    "    if norm_type == 'l2':\n",
    "        direction = grad / (torch.norm(grad, dim=-1, keepdim=True) + eps)\n",
    "    elif norm_type == 'l1':\n",
    "        direction = grad.sign()\n",
    "    else:\n",
    "        direction = grad / (grad.abs().max(-1, keepdim=True)[0] + eps)\n",
    "    return direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_adversarial_loss(model:nn.Module, embed:Tensor, logits:Tensor, \n",
    "                             noise_var:float=1e-5, step_size:float=1e-3, k:int=1,\n",
    "                             noise_gamma:float=1e-6):\n",
    "    \"This is nice docstring\"\n",
    "    noise = embed.data.new(embed.size()).normal_(0, noise_var) \n",
    "    noise.requires_grad_();\n",
    "\n",
    "    for _ in range(k):\n",
    "        newembed = embed + noise\n",
    "        adv_logits = model(inputs_embeds=newembed).logits\n",
    "\n",
    "        adv_loss = KL(adv_logits, logits.detach(), reduction=\"batchmean\") \n",
    "        delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True)\n",
    "\n",
    "        norm = LA.norm(delta_grad) \n",
    "        if (torch.isnan(norm) or torch.isinf(norm)):\n",
    "            break\n",
    "\n",
    "        noise = noise + delta_grad * step_size\n",
    "        noise = adv_project(noise, norm_type=\"fro\", eps=noise_gamma)\n",
    "\n",
    "    newembed = embed + noise\n",
    "    adv_logits = model(inputs_embeds=newembed).logits\n",
    "\n",
    "    adv_loss_f = KL(adv_logits, logits.detach())\n",
    "    adv_loss_b = KL(logits, adv_logits.detach())\n",
    "    return adv_loss_f + adv_loss_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALUMCallback(Callback):\n",
    "    \"ALUM callback (draft)\"\n",
    "    run_valid = False\n",
    "    order = GradientAccumulation.order-1\n",
    "    @delegates(compute_adversarial_loss)\n",
    "    def __init__(self, m:nn.Module, alpha:float=1., start_epoch:int=1, **kwargs):\n",
    "        self.hook = None\n",
    "        self.adv_loss_func = partial(compute_adversarial_loss, **kwargs) if kwargs else compute_adversarial_loss\n",
    "        store_attr()\n",
    "\n",
    "    def before_batch(self):\n",
    "        if (self.hook is None) and (self.epoch >= self.start_epoch):\n",
    "            self.hook = Hook(self.m, hook_out)\n",
    "            print(f'Starting virtual adversarial training at epoch {self.epoch}')\n",
    "\n",
    "    def after_loss(self):\n",
    "        if self.epoch >= self.start_epoch:\n",
    "            embed, logits = self.hook.stored, self.pred\n",
    "            adv_loss = self.adv_loss_func(self.model.hf_model, embed, logits)\n",
    "            self.learn.loss_grad += adv_loss * self.alpha\n",
    "\n",
    "    def after_fit(self):\n",
    "        if self.hook is not None: self.hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "learn = Learner(dls,\n",
    "                model,\n",
    "                opt_func=RAdam,\n",
    "                metrics=[accuracy],\n",
    "                cbs=[HF_BaseModelCallback, GradientAccumulation(8)],\n",
    "                splitter=hf_splitter).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.add_cb(ALUMCallback(learn.model.hf_model.base_model.embeddings, start_epoch=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not gather input dimensions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.228204</td>\n",
       "      <td>0.244110</td>\n",
       "      <td>0.900800</td>\n",
       "      <td>10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.170476</td>\n",
       "      <td>0.175666</td>\n",
       "      <td>0.930080</td>\n",
       "      <td>20:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.104206</td>\n",
       "      <td>0.156094</td>\n",
       "      <td>0.941760</td>\n",
       "      <td>20:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.063551</td>\n",
       "      <td>0.150507</td>\n",
       "      <td>0.943760</td>\n",
       "      <td>20:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <finalize object at 0x7feb41aa8800; dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/weakref.py\", line 572, in __call__\n",
      "    return info.func(*info.args, **(info.kwargs or {}))\n",
      "  File \"/usr/lib/python3.7/tempfile.py\", line 936, in _cleanup\n",
      "    _rmtree(name)\n",
      "  File \"/usr/lib/python3.7/shutil.py\", line 485, in rmtree\n",
      "    onerror(os.lstat, path, sys.exc_info())\n",
      "  File \"/usr/lib/python3.7/shutil.py\", line 483, in rmtree\n",
      "    orig_st = os.lstat(path)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpdpmakwvl'\n",
      "Exception ignored in: <finalize object at 0x7feb41aa8720; dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/weakref.py\", line 572, in __call__\n",
      "    return info.func(*info.args, **(info.kwargs or {}))\n",
      "  File \"/usr/lib/python3.7/tempfile.py\", line 936, in _cleanup\n",
      "    _rmtree(name)\n",
      "  File \"/usr/lib/python3.7/shutil.py\", line 485, in rmtree\n",
      "    onerror(os.lstat, path, sys.exc_info())\n",
      "  File \"/usr/lib/python3.7/shutil.py\", line 483, in rmtree\n",
      "    orig_st = os.lstat(path)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmp3v205bob'\n",
      "Exception ignored in: <finalize object at 0x7feb41aa87e0; dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/weakref.py\", line 572, in __call__\n",
      "    return info.func(*info.args, **(info.kwargs or {}))\n",
      "  File \"/usr/lib/python3.7/tempfile.py\", line 936, in _cleanup\n",
      "    _rmtree(name)\n",
      "  File \"/usr/lib/python3.7/shutil.py\", line 485, in rmtree\n",
      "    onerror(os.lstat, path, sys.exc_info())\n",
      "  File \"/usr/lib/python3.7/shutil.py\", line 483, in rmtree\n",
      "    orig_st = os.lstat(path)\n",
      "Exception ignored in: <finalize object at 0x7feb41aa8800; dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/weakref.py\", line 572, in __call__\n",
      "    return info.func(*info.args, **(info.kwargs or {}))\n",
      "  File \"/usr/lib/python3.7/tempfile.py\", line 936, in _cleanup\n",
      "    _rmtree(name)\n",
      "  File \"/usr/lib/python3.7/shutil.py\", line 485, in rmtree\n",
      "    onerror(os.lstat, path, sys.exc_info())\n",
      "  File \"/usr/lib/python3.7/shutil.py\", line 483, in rmtree\n",
      "    orig_st = os.lstat(path)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpdpmakwvl'\n",
      "Exception ignored in: <finalize object at 0x7feb41aa8720; dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/weakref.py\", line 572, in __call__\n",
      "    return info.func(*info.args, **(info.kwargs or {}))\n",
      "  File \"/usr/lib/python3.7/tempfile.py\", line 936, in _cleanup\n",
      "    _rmtree(name)\n",
      "  File \"/usr/lib/python3.7/shutil.py\", line 485, in rmtree\n",
      "    onerror(os.lstat, path, sys.exc_info())\n",
      "  File \"/usr/lib/python3.7/shutil.py\", line 483, in rmtree\n",
      "    orig_st = os.lstat(path)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmp3v205bob'\n",
      "Exception ignored in: <finalize object at 0x7feb41aa87e0; dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/weakref.py\", line 572, in __call__\n",
      "    return info.func(*info.args, **(info.kwargs or {}))\n",
      "  File \"/usr/lib/python3.7/tempfile.py\", line 936, in _cleanup\n",
      "    _rmtree(name)\n",
      "  File \"/usr/lib/python3.7/shutil.py\", line 485, in rmtree\n",
      "    onerror(os.lstat, path, sys.exc_info())\n",
      "  File \"/usr/lib/python3.7/shutil.py\", line 483, in rmtree\n",
      "    orig_st = os.lstat(path)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpdq35_27h'\n",
      "Exception ignored in: <finalize object at 0x7feb41aa8d00; dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/weakref.py\", line 572, in __call__\n",
      "    return info.func(*info.args, **(info.kwargs or {}))\n",
      "  File \"/usr/lib/python3.7/tempfile.py\", line 936, in _cleanup\n",
      "    _rmtree(name)\n",
      "  File \"/usr/lib/python3.7/shutil.py\", line 485, in rmtree\n",
      "    onerror(os.lstat, path, sys.exc_info())\n",
      "  File \"/usr/lib/python3.7/shutil.py\", line 483, in rmtree\n",
      "    orig_st = os.lstat(path)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmp547xdkjj'\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:760: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not return a \"\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpdq35_27h'\n",
      "Exception ignored in: <finalize object at 0x7feb41aa8d00; dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/weakref.py\", line 572, in __call__\n",
      "    return info.func(*info.args, **(info.kwargs or {}))\n",
      "  File \"/usr/lib/python3.7/tempfile.py\", line 936, in _cleanup\n",
      "    _rmtree(name)\n",
      "  File \"/usr/lib/python3.7/shutil.py\", line 485, in rmtree\n",
      "    onerror(os.lstat, path, sys.exc_info())\n",
      "  File \"/usr/lib/python3.7/shutil.py\", line 483, in rmtree\n",
      "    orig_st = os.lstat(path)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmp547xdkjj'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting virtual adversarial training at epoch 1\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(4, 2e-5, cbs=WandbCallback(log_preds=False, log_model=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
