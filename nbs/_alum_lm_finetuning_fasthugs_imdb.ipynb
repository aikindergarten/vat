{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr 30 09:31:49 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   61C    P0    30W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for fasthugs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for vat (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install -Uqq transformers datasets wandb \n",
    "    !pip install -Uqq fastcore onnx sentencepiece\n",
    "    !pip install -Uqq --no-deps fastai\n",
    "    !pip install -q git+git://github.com/aikindergarten/fasthugs.git\n",
    "    !pip install -q git+git://github.com/aikindergarten/vat.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *\n",
    "from fastai.callback.wandb import *\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from fasthugs.learner import TransLearner\n",
    "from fasthugs.data import TransformersTextBlock\n",
    "\n",
    "from vat.core import ALUMCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(fn):\n",
    "    return open(fn).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_name = 'imdb'\n",
    "model_name = 'microsoft/deberta-base'\n",
    "\n",
    "max_len = 512\n",
    "bs = 4\n",
    "val_bs = bs*4\n",
    "\n",
    "lr = 2e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "WANDB_NAME = f'{ds_name}-{model_name}'\n",
    "GROUP = f'{ds_name}-{model_name}-simple-{lr:.0e}'\n",
    "NOTES = f'finetuning {model_name} with RAdam lr={lr:.0e}'\n",
    "CONFIG = {}\n",
    "TAGS =[model_name, ds_name, 'radam', 'alum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfastai_community\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">imdb-microsoft/deberta-base</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/fastai_community/vat\" target=\"_blank\">https://wandb.ai/fastai_community/vat</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/fastai_community/vat/runs/3rod768w\" target=\"_blank\">https://wandb.ai/fastai_community/vat/runs/3rod768w</a><br/>\n",
       "                Run data is saved locally in <code>/content/wandb/run-20210430_093208-3rod768w</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(reinit=True, project=\"vat\", entity=\"fastai_community\",\n",
    "           name=WANDB_NAME, group=GROUP, notes=NOTES, tags=TAGS, config=CONFIG);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Match 1: Tag Team Table Match Bubba Ray and Spike Dudley vs Eddie Guerrero and Chris Benoit Bubba Ray and Spike Dudley started things off with a Tag Team Table Match against Eddie Guerrero and Chris Benoit. According to the rules of the match, both opponents have to go through tables in order to get the win. Benoit and Guerrero heated up early on by taking turns hammering first Spike and then Bubba Ray. A German suplex by Benoit to Bubba took the wind out of the Dudley brother. Spike tried to help his brother, but the referee restrained him while Benoit and Guerrero ganged up on him in the corner. With Benoit stomping away on Bubba, Guerrero set up a table outside. Spike dashed into the ring and somersaulted over the top rope onto Guerrero on the outside! After recovering and taking care of Spike, Guerrero slipped a table</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"La Maman et la putain\" is the beautifulest film of all time. And what's most moving about it may be the relation between reality and art the movie deals with, which is directly inspired by Proust's \"A la Recherche du temps perdu\".&lt;br /&gt;&lt;br /&gt;Indeed, \"La Maman et la putain\" and \"In search of lost time\" apparently tell the same story : the one of the failure of love, which repeats itself endlessly. The first woman's name is always Gilberte, and the second woman appears like a twisted and deformed double of Gilberte : Veronika is like a \"whore Gilberte\", beautiful like the night, whereas Gilberte was pure, and \"beautiful like the day\". After the failure of the first love, a second love begins, but this one is like already doomed by the first one. Veronika takes the place of Gilberte, in Alexandre's life and in the movie. She progressively eclipses</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I watched Grendel the other night and am compelled to put together a Public Service Announcement.&lt;br /&gt;&lt;br /&gt;Grendel is another version of Beowulf, the thousand-year-old Anglo-Saxon epic poem. The SciFi channel has a growing catalog of inoffensive and uninteresting movies, and the previews promised an inauthentic low-budget mini-epic, but this one refused to let me switch channels. It was staggeringly, overwhelmingly, bad. I watched in fascination and horror at the train wreck you couldn't tear your eyes away from. I reached for a notepad and managed to capture part of what I was seeing. The following may contain spoilers or might just save your sanity. You've been warned.&lt;br /&gt;&lt;br /&gt;- Just to get it over with, Beowulf's warriors wore horned helmets. Trivial issue compared to what came after. It also appears that the helmets were in a bin and handed to whichever actor wandered by next. Fit, appearance and function</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This project was originally conceived as the movie version of popular Japanese manga SlamDunk! and that's not something new to Jay Chou, who made his movie debut playing a character from another wildly popular manga Initial D. Along the way, it was decided to incorporate some kung fu into the movie, so hence the title, even if the idea wasn't very original, with Stephen Chow's Shaolin Soccer coming to mind with martial arts and ball games combined.&lt;br /&gt;&lt;br /&gt;However, and thankfully, those scenes where kung fu actually influenced the games were kept to a bare minimum, and in Kung Fu Dunk, really quite unnecessary, because they don't add much to the plot nor drum up much excitement, and at most offered some cheap laughs and reminisced about the time when Stephen Chow used kung fu in football games. Jay Chou is comfortable in his role as a martial artist Fang</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dblock = DataBlock(blocks = [TransformersTextBlock(pretrained_model_name=model_name), CategoryBlock()],\n",
    "                   get_items=get_text_files,\n",
    "                   get_x=read_text,\n",
    "                   get_y=parent_label,\n",
    "                   splitter=GrandparentSplitter(valid_name='test'))\n",
    "\n",
    "dls = dblock.dataloaders(path, bs=bs, val_bs=val_bs)\n",
    "dls.show_batch(max_n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALUM finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "learn = TransLearner(dls, model,\n",
    "                opt_func=RAdam,\n",
    "                cbs=[GradientAccumulation(16)],\n",
    "                metrics=[accuracy]).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.add_cb(ALUMCallback(learn.model.base_model.embeddings, start_epoch=0, alpha=0.7));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not gather input dimensions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.328478</td>\n",
       "      <td>0.227183</td>\n",
       "      <td>0.947080</td>\n",
       "      <td>1:11:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.098229</td>\n",
       "      <td>0.117810</td>\n",
       "      <td>0.956760</td>\n",
       "      <td>1:11:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.055866</td>\n",
       "      <td>0.112570</td>\n",
       "      <td>0.959520</td>\n",
       "      <td>1:11:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.031281</td>\n",
       "      <td>0.115716</td>\n",
       "      <td>0.960280</td>\n",
       "      <td>1:11:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting virtual adversarial training at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <finalize object at 0x7fa510d4c930; dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/weakref.py\", line 572, in __call__\n",
      "    return info.func(*info.args, **(info.kwargs or {}))\n",
      "  File \"/usr/lib/python3.7/tempfile.py\", line 936, in _cleanup\n",
      "    _rmtree(name)\n",
      "  File \"/usr/lib/python3.7/shutil.py\", line 485, in rmtree\n",
      "    onerror(os.lstat, path, sys.exc_info())\n",
      "  File \"/usr/lib/python3.7/shutil.py\", line 483, in rmtree\n",
      "    orig_st = os.lstat(path)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpuqd1tkhg'\n",
      "Exception ignored in: <finalize object at 0x7fa510d4c930; dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/weakref.py\", line 572, in __call__\n",
      "    return info.func(*info.args, **(info.kwargs or {}))\n",
      "  File \"/usr/lib/python3.7/tempfile.py\", line 936, in _cleanup\n",
      "    _rmtree(name)\n",
      "  File \"/usr/lib/python3.7/shutil.py\", line 485, in rmtree\n",
      "    onerror(os.lstat, path, sys.exc_info())\n",
      "  File \"/usr/lib/python3.7/shutil.py\", line 483, in rmtree\n",
      "    orig_st = os.lstat(path)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpuqd1tkhg'\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(4, 2e-5, cbs=WandbCallback(log_preds=False, log_model=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
